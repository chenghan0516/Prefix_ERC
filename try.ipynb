{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_virtual_tokens: 7\n",
      "num_subjects: 2\n",
      "padding_idx: 6\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModelForSeq2SeqLM, PromptEncoderConfig, PromptEncoderReparameterizationType, get_peft_model, get_peft_model_state_dict, set_peft_model_state_dict\n",
    "from peft.tuners.prefix_tuning import PrefixEncoder\n",
    "from peft.tuners.p_tuning import PromptEncoder\n",
    "from peft.utils import _get_batch_size, PeftType, TaskType, TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING, map_cache_to_layer_device_map\n",
    "from transformers import PreTrainedModel, DynamicCache, EncoderDecoderCache\n",
    "from typing import Optional\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class AbstractPromptEncoderConfig(PromptEncoderConfig):\n",
    "    \"\"\"\n",
    "    This is the configuration class to store the configuration of a [`PromptEncoder`].\n",
    "\n",
    "    Args:\n",
    "        encoder_reparameterization_type (Union[[`PromptEncoderReparameterizationType`], `str`]):\n",
    "            The type of reparameterization to use.\n",
    "        encoder_hidden_size (`int`): The hidden size of the prompt encoder.\n",
    "        encoder_num_layers (`int`): The number of layers of the prompt encoder.\n",
    "        encoder_dropout (`float`): The dropout probability of the prompt encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    num_subjects: int = field(\n",
    "        default=8,\n",
    "        metadata={\"help\": \"The number of subjects of the prompt encoder\"},\n",
    "    )\n",
    "    padding_idx: int = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The padding index of the prompt encoder\"},\n",
    "    )\n",
    "    def __post_init__(self):\n",
    "        super().__post_init__()\n",
    "        self.peft_type = PeftType.P_TUNING #TODO: switch to APTuning\n",
    "\n",
    "\n",
    "class AbstractPromptEncoder(PromptEncoder):\n",
    "    def __init__(self, config):\n",
    "\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.num_subjects = config.num_subjects\n",
    "        self.total_virtual_tokens = config.num_virtual_tokens * config.num_subjects * config.num_transformer_submodules\n",
    "        if config.padding_idx is not None:\n",
    "            self.padding_idx = config.padding_idx\n",
    "        else:\n",
    "            self.padding_idx = self.total_virtual_tokens\n",
    "            self.total_virtual_tokens += 1\n",
    "\n",
    "        print(f\"total_virtual_tokens: {self.total_virtual_tokens}\")\n",
    "        print(f\"num_subjects: {self.num_subjects}\")\n",
    "        print(f\"padding_idx: {self.padding_idx}\")\n",
    "        # embedding\n",
    "        self.embedding = torch.nn.Embedding(self.total_virtual_tokens, self.token_dim, padding_idx=self.padding_idx)\n",
    "        if not config.inference_mode:\n",
    "            if self.encoder_type == PromptEncoderReparameterizationType.LSTM:\n",
    "                lstm_dropout = config.encoder_dropout\n",
    "                num_layers = config.encoder_num_layers\n",
    "                # LSTM\n",
    "                self.lstm_head = torch.nn.LSTM(\n",
    "                    input_size=self.input_size,\n",
    "                    hidden_size=self.hidden_size,\n",
    "                    num_layers=num_layers,\n",
    "                    dropout=lstm_dropout,\n",
    "                    bidirectional=True,\n",
    "                    batch_first=True,\n",
    "                )\n",
    "\n",
    "                self.mlp_head = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(self.hidden_size * 2, self.hidden_size * 2),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(self.hidden_size * 2, self.output_size),\n",
    "                )\n",
    "\n",
    "            elif self.encoder_type == PromptEncoderReparameterizationType.MLP:\n",
    "                encoder_num_layers_default = AbstractPromptEncoderConfig.encoder_num_layers\n",
    "                if config.encoder_num_layers != encoder_num_layers_default:\n",
    "                    warnings.warn(\n",
    "                        f\"for {self.encoder_type.value}, the argument `encoder_num_layers` is ignored. \"\n",
    "                        f\"Exactly {encoder_num_layers_default} MLP layers are used.\"\n",
    "                    )\n",
    "                layers = [\n",
    "                    torch.nn.Linear(self.input_size, self.hidden_size),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(self.hidden_size, self.hidden_size),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(self.hidden_size, self.output_size),\n",
    "                ]\n",
    "                self.mlp_head = torch.nn.Sequential(*layers)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"Prompt encoder type not recognized. Please use one of MLP (recommended) or LSTM.\")\n",
    "\n",
    "batch_size=2\n",
    "num_virtual_tokens = 3\n",
    "num_subjects = 2\n",
    "\n",
    "peft_config = AbstractPromptEncoderConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, num_virtual_tokens=num_virtual_tokens, num_subjects=num_subjects, token_dim=5, num_transformer_submodules=1, encoder_hidden_size=10)\n",
    "\n",
    "temp = AbstractPromptEncoder(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(temp(torch.randint(num_virtual_tokens*num_subjects, (batch_size,num_virtual_tokens))).shape) # (2, 3, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CARCVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
